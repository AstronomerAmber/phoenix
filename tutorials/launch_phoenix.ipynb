{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "tokens = encoding.encode(prompt)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitbookLoader\n",
    "\n",
    "# loader = GitbookLoader(\"https://app.gitbook.com/o/-MB4weB2E-qpBe07nmSL/s/ShR775Rt7OzHRfy5j2Ks/\")\n",
    "loader = GitbookLoader(\"https://docs.arize.com/phoenix/\", load_all_paths=True)\n",
    "documents = loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import GitbookLoader\n",
    "\n",
    "\n",
    "def build_database(embeddings):\n",
    "    loader = GitbookLoader(\"https://docs.arize.com/phoenix/\", load_all_paths=True)\n",
    "    documents = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter()\n",
    "    texts = splitter.split_documents(documents)\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    return db\n",
    "\n",
    "def save_database(database, save_path):\n",
    "    database.save_local(save_path)\n",
    "    \n",
    "def load_database(save_path, embeddings):\n",
    "    return FAISS.load_local(save_path, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "database_path = \"docs_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database = build_database(embeddings)\n",
    "save_database(database, database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = load_database(database_path, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = database.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    # The object that will help select examples\n",
    "    example_selector=example_selector,\n",
    "    \n",
    "    # Your prompt\n",
    "    example_prompt=example_prompt,\n",
    "    \n",
    "    # Customizations that will be added to the top and bottom of your prompt\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix=\"Input: {noun}\\nOutput:\",\n",
    "    \n",
    "    # What inputs your prompt will receive\n",
    "    input_variables=[\"noun\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"how many phoenix datasets do i need to define?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "loader = TextLoader(\"/Users/xandersong/phoenix/tutorials/schema_examples.md\")\n",
    "documents = loader.load()\n",
    "splitter = MarkdownTextSplitter()\n",
    "texts = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"description\": \"dataframe with timestamp_column_name, prediction_score_column_name, prediction_label_column_name, and actual_label_column_name\",\n",
    "        \"dataframe\": \"\"\"pd.DataFrame([\n",
    "    [pd.to_datetime('2023-03-01 02:02:19'), 0.91, 'click', 'click'],\n",
    "    [pd.to_datetime('2023-02-17 23:45:48'), 0.37, 'no_click', 'no_click'],\n",
    "    [pd.to_datetime('2023-01-30 15:30:03'), 0.54, 'click', 'no_click'],\n",
    "    [pd.to_datetime('2023-02-03 19:56:09'), 0.74, 'click', 'click'],\n",
    "    [pd.to_datetime('2023-02-24 04:23:43'), 0.37, 'no_click', 'click']\n",
    "], columns=['timestamp', 'prediction_score', 'prediction', 'target'])\"\"\",\n",
    "        \"schema\": \"\"\"px.Schema(\n",
    "    timestamp_column_name=\"timestamp\",\n",
    "    prediction_score_column_name=\"prediction_score\",\n",
    "    prediction_label_column_name=\"prediction\",\n",
    "    actual_label_column_name=\"target\",\n",
    ")\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"dataframe with prediction_label_column_name, actual_label_column_name, feature_column_names, tag_column_names\",\n",
    "        \"dataframe\": \"\"\"pd.DataFrame({\n",
    "    'fico_score': [578, 507, 656, 414, 512],\n",
    "    'merchant_id': ['Scammeds', 'Schiller Ltd', 'Kirlin and Sons', 'Scammeds', 'Champlin and Sons'],\n",
    "    'loan_amount': [4300, 21000, 18000, 18000, 20000],\n",
    "    'annual_income': [62966, 52335, 94995, 32034, 46005],\n",
    "    'home_ownership': ['RENT', 'RENT', 'MORTGAGE', 'LEASE', 'OWN'],\n",
    "    'num_credit_lines': [110, 129, 31, 81, 148],\n",
    "    'inquests_in_last_6_months': [0, 0, 0, 2, 1],\n",
    "    'months_since_last_delinquency': [0, 23, 0, 0, 0],\n",
    "    'age': [25, 78, 54, 34, 49],\n",
    "    'gender': ['male', 'female', 'female', 'male', 'male'],\n",
    "    'predicted': ['not_fraud', 'not_fraud', 'uncertain', 'fraud', 'uncertain'],\n",
    "    'target': ['fraud', 'not_fraud', 'uncertain', 'not_fraud', 'uncertain']\n",
    "})\"\"\",\n",
    "        \"schema\": \"\"\"px.Schema(\n",
    "    prediction_label_column_name=\"predicted\",\n",
    "    actual_label_column_name=\"target\",\n",
    "    feature_column_names=[\n",
    "        \"fico_score\",\n",
    "        \"merchant_id\",\n",
    "        \"loan_amount\",\n",
    "        \"annual_income\",\n",
    "        \"home_ownership\",\n",
    "        \"num_credit_lines\",\n",
    "        \"inquests_in_last_6_months\",\n",
    "        \"months_since_last_delinquency\",\n",
    "    ],\n",
    "    tag_column_names=[\n",
    "        \"age\",\n",
    "        \"gender\",\n",
    "    ],\n",
    ")\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"example with prediction_label_column_name, actual_label_column_name, (embedding_feature_column_names with vector_column_name)\",\n",
    "        \"dataframe\": \"\"\"pd.DataFrame({\n",
    "    'predicted': ['fraud', 'fraud', 'not_fraud', 'not_fraud', 'uncertain'],\n",
    "    'target': ['not_fraud', 'not_fraud', 'not_fraud', 'not_fraud', 'uncertain'],\n",
    "    'embedding_vector': [[-0.97, 3.98, -0.03, 2.92], [3.20, 3.95, 2.81, -0.09], [-0.49, -0.62, 0.08, 2.03], [1.69, 0.01, -0.76, 3.64], [1.46, 0.69, 3.26, -0.17]],\n",
    "    'fico_score': [604, 612, 646, 560, 636],\n",
    "    'merchant_id': ['Leannon Ward', 'Scammeds', 'Leannon Ward', 'Kirlin and Sons', 'Champlin and Sons'],\n",
    "    'loan_amount': [22000, 7500, 32000, 19000, 10000],\n",
    "    'annual_income': [100781, 116184, 73666, 38589, 100251],\n",
    "    'home_ownership': ['RENT', 'MORTGAGE', 'RENT', 'MORTGAGE', 'MORTGAGE'],\n",
    "    'num_credit_lines': [108, 42, 131, 131, 10],\n",
    "    'inquests_in_last_6_months': [0, 2, 0, 0, 0],\n",
    "    'months_since_last_delinquency': [0, 56, 0, 0, 3]\n",
    "})\"\"\",\n",
    "        \"schema\": \"\"\"px.Schema(\n",
    "    prediction_label_column_name=\"predicted\",\n",
    "    actual_label_column_name=\"target\",\n",
    "    embedding_feature_column_names={\n",
    "        \"transaction_embeddings\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"embedding_vector\"\n",
    "        ),\n",
    "    },\n",
    ")\"\"\",\n",
    "    },    \n",
    "    {\n",
    "        \"description\": \"dataframe with actual_label_column_name, (embedding_feature_column_names with vector_column_name and link_to_data_column_name)\",\n",
    "        \"dataframe\": \"\"\"pd.DataFrame({\n",
    "    'defective': ['okay', 'defective', 'okay', 'defective', 'okay'],\n",
    "    'image': ['https://www.example.com/image0.jpeg', 'https://www.example.com/image1.jpeg', 'https://www.example.com/image2.jpeg', 'https://www.example.com/image3.jpeg', 'https://www.example.com/image4.jpeg'],\n",
    "    'image_vector': [[1.73, 2.67, 2.91, 1.79, 1.29], [2.18, -0.21, 0.87, 3.84, -0.97], [3.36, -0.62, 2.40, -0.94, 3.69], [2.77, 2.79, 3.36, 0.60, 3.10], [1.79, 2.06, 0.53, 3.58, 0.24]]\n",
    "})\"\"\",\n",
    "        \"schema\": \"\"\"px.Schema(\n",
    "    actual_label_column_name=\"defective\",\n",
    "    embedding_feature_column_names={\n",
    "        \"image_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"image_vector\",\n",
    "            link_to_data_column_name=\"image\",\n",
    "        ),\n",
    "    },\n",
    ")\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"dataframe with actual_label_column_name, feature_column_names, tag_column_names, (embedding_feature_column_names with vector_column_name and raw_data_column_name)\",\n",
    "        \"dataframe\": \"\"\"pd.DataFrame({\n",
    "    'defective': ['okay', 'defective', 'okay', 'defective', 'okay'],\n",
    "    'image': ['https://www.example.com/image0.jpeg', 'https://www.example.com/image1.jpeg', 'https://www.example.com/image2.jpeg', 'https://www.example.com/image3.jpeg', 'https://www.example.com/image4.jpeg'],\n",
    "    'image_vector': [[1.73, 2.67, 2.91, 1.79, 1.29], [2.18, -0.21, 0.87, 3.84, -0.97], [3.36, -0.62, 2.40, -0.94, 3.69], [2.77, 2.79, 3.36, 0.60, 3.10], [1.79, 2.06, 0.53, 3.58, 0.24]]\n",
    "})\"\"\",\n",
    "        \"schema\": \"\"\"px.Schema(\n",
    "    actual_label_column_name=\"sentiment\",\n",
    "    feature_column_names=[\n",
    "        \"category\",\n",
    "    ],\n",
    "    tag_column_names=[\n",
    "        \"name\",\n",
    "    ],\n",
    "    embedding_feature_column_names={\n",
    "        \"product_review_embeddings\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"text_vector\",\n",
    "            raw_data_column_name=\"text\",\n",
    "        ),\n",
    "    },\n",
    ")\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "examples_prompt = \"\"\n",
    "for example in examples:\n",
    "    examples_prompt += f\"\"\"Example: {example[\"description\"]}\n",
    "Dataframe:\n",
    "\n",
    "```python\n",
    "{example[\"dataframe\"]}\n",
    "```\n",
    "\n",
    "Schema:\n",
    "\n",
    "```python\n",
    "{example[\"schema\"]}\n",
    "```\n",
    "\"\"\"\n",
    "print(examples_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/xandersong/phoenix/tutorials/api_reference.md\") as f:\n",
    "    api_docs = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_parquet(\"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/cv/human-actions/human_actions_training.parquet\")\n",
    "\n",
    "sampled_dataframe = dataframe.head(1)\n",
    "column_to_type = {}\n",
    "for column in sampled_dataframe.columns:\n",
    "    column_to_type[column] = repr(type(sampled_dataframe[column].iloc[0]))[8:-2]\n",
    "dataframe_column_to_type = \"\\n\".join([f\"{column}: {type_string}\" for column, type_string in column_to_type.items()])\n",
    "print(dataframe_column_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given an input dataframe, suggest a schema that describes that dataframe. I've included the API reference and some examples before giving a description of the input dataframe. Return a syntactic Python code snippet of the form `px.Schema({fill this in})` that is syntactic and can be copy-pasted. Do not use the backtick symbol (`) in your response.\n",
    "\n",
    "API Documentation:\n",
    "{api}\n",
    "\n",
    "Examples:\n",
    "\n",
    "{ex}\n",
    "\n",
    "Input Dataframe Columns to Data Type:\n",
    "{df}\n",
    "\n",
    "Schema:\n",
    "\"\"\"\n",
    "\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SystemMessagePromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSystemMessagePromptTemplate\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_template(template)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SystemMessagePromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "SystemMessagePromptTemplate.from_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"api\", \"ex\", \"df\"],\n",
    "    template=template,\n",
    ").format(api=api_docs, ex=examples_prompt, df=dataframe_column_to_type)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "# model_name=\"gpt-4\"\n",
    "llm = OpenAI(model_name=model_name)\n",
    "output = llm(prompt)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
